{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "dataset = 'agnews'\n",
    "\n",
    "home = str(Path.home())\n",
    "root_dir = os.path.join(home, 'datasets', dataset)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "def create_dataframe(doc_tf, doc_targets):\n",
    "    docs = []\n",
    "    for i, bow in enumerate(doc_tf):\n",
    "        d = {'doc_id': i, 'bow': bow, 'label': doc_targets[i]}\n",
    "        docs.append(d)\n",
    "    return pd.DataFrame.from_dict(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = os.path.join(root_dir, 'train.csv')\n",
    "df = pd.read_csv(train_fn, header=None)\n",
    "df.columns = ['label', 'title', 'body']\n",
    "train_content = list(df.body)\n",
    "train_label = list(df.label - 1)\n",
    "\n",
    "test_fn = os.path.join(root_dir, 'test.csv')\n",
    "df = pd.read_csv(test_fn, header=None)\n",
    "df.columns = ['label', 'title', 'body']\n",
    "test_content = list(df.body)\n",
    "test_label = list(df.label - 1)\n",
    "\n",
    "################################################################################################\n",
    "count_vect = CountVectorizer(stop_words='english', max_features=10000, max_df=0.8, min_df=3)\n",
    "train_tf = count_vect.fit_transform(train_content)\n",
    "test_tf = count_vect.transform(test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_dataframe(train_tf, train_label)\n",
    "test_df = create_dataframe(test_tf, test_label)\n",
    "\n",
    "def get_doc_length(doc_bow):\n",
    "    return doc_bow.sum()\n",
    "\n",
    "# remove an empty document\n",
    "train_df = train_df[train_df.bow.apply(get_doc_length) > 0]\n",
    "test_df = test_df[test_df.bow.apply(get_doc_length) > 0]\n",
    "\n",
    "# split test and cv\n",
    "num_train = len(train_df)\n",
    "num_test = len(test_df) // 2\n",
    "num_cv = len(test_df) - num_test\n",
    "\n",
    "test_df = shuffle(test_df)\n",
    "cv_df = test_df.iloc[:num_cv]\n",
    "test_df = test_df.iloc[num_cv:]\n",
    "\n",
    "# set doc_id as an index\n",
    "train_df.set_index('doc_id', inplace=True)\n",
    "test_df.set_index('doc_id', inplace=True)\n",
    "cv_df.set_index('doc_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the dataset\n",
    "if dataset == 'dbpedia':\n",
    "    train_df = train_df.sample(n=50000, replace=False)\n",
    "    test_df = test_df.sample(n=10000, replace=False)\n",
    "    cv_df = cv_df.sample(n=10000, replace=False)\n",
    "elif dataset == 'agnews':\n",
    "    train_df = train_df.sample(n=30000, replace=False)\n",
    "    #test_df = test_df.sample(n=10000, replace=False)\n",
    "    #cv_df = cv_df.sample(n=10000, replace=False)\n",
    "\n",
    "# save the dataframes\n",
    "train_df.to_pickle('../dataset/{}/train.df.pkl'.format(dataset))\n",
    "test_df.to_pickle('../dataset/{}/test.df.pkl'.format(dataset))\n",
    "cv_df.to_pickle('../dataset/{}/cv.df.pkl'.format(dataset))\n",
    "\n",
    "# save vocab\n",
    "with open('../dataset/{}/vocab.pkl'.format(dataset), 'wb') as handle:\n",
    "    pickle.dump(count_vect.vocabulary_, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_df.label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research2018",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
